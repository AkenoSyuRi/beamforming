{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 空间定点宽带Beamforming展示\n",
    "\n",
    "demo提供了空间定点beamforming语音增强的实现， 采用的是CBF方法， 稍微更改可以变成MVDR方法， 但个人理解MVDR方法只是分辨率稍高，但需要计算矩阵的逆大大增加计算量，因此建议使用传统的CBF方法就好。\n",
    "\n",
    "本次demo中， 我引入了三个声源， 控制第一个声源音量为-20dB， 另外两个声源的音量为-26dB， 通过麦克风阵列向第一个声源位置进行beamforming波束形成，实现信号增强。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Beamform.BFModel import beamforming_model\n",
    "from Beamform.CMA100 import CMA100\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Beamform.tools import ConvertToTargetDb, NormLength, NormAmplitude, CalRms\n",
    "import IPython.display as ipd\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data, _ = librosa.load('./test_audios/1.wav', sr=16000)\n",
    "noise_data1, _ = librosa.load('./test_audios/A8_0.wav', sr=16000)\n",
    "noise_data2, _ = librosa.load('./noise/noise1.wav', sr=16000)\n",
    "audio_data = NormLength(audio_data, num_samples=4*16000)\n",
    "noise_data1 = NormLength(noise_data1, num_samples=4*16000)\n",
    "noise_data2 = NormLength(noise_data2, num_samples=4*16000)\n",
    "\n",
    "audio_data = ConvertToTargetDb(audio_data, -20)\n",
    "noise_data1 = ConvertToTargetDb(noise_data1, -26)\n",
    "noise_data2 = ConvertToTargetDb(noise_data2, -26)\n",
    "\n",
    "# 进行短时傅里叶变换， 准备模拟流式处理\n",
    "audio_rfft = librosa.stft(audio_data, n_fft=512, win_length=512, hop_length=128)\n",
    "noise1_rfft = librosa.stft(noise_data1, n_fft=512, win_length=512, hop_length=128)\n",
    "noise2_rfft = librosa.stft(noise_data2, n_fft=512, win_length=512, hop_length=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置我们信号源位置。\n",
    "audio_x, audio_y, audio_z = 2.0, 0.0, 0.0\n",
    "noise1_x, noise1_y, noise1_z = -1.4, -1.4, 0.0\n",
    "noise2_x, noise2_y, noise2_z = -2.0, 0.0, 0.0\n",
    "\n",
    "# 初始化cma100阵列\n",
    "cma100 = CMA100(fs= 16000, L=512)\n",
    "\n",
    "# 模拟阵列流式接受信号， 并处理的过程\n",
    "frameLength = 512\n",
    "N = audio_rfft.shape[1]\n",
    "enhancedAudio = np.zeros_like(audio_rfft)\n",
    "micAudio = np.zeros_like(audio_rfft)\n",
    "\n",
    "# 流式处理：\n",
    "for i in range(N):\n",
    "    cma100.reset()\n",
    "    cma100.add_signal(S_x = audio_x, S_y = audio_y, S_z = audio_z, signal_rfft = audio_rfft[:, i]) # 接受第一个信号源\n",
    "    cma100.add_signal(S_x = noise1_x, S_y = noise1_y, S_z = noise1_z, signal_rfft = noise1_rfft[:, i]) # 接受第二个信号源\n",
    "    cma100.add_signal(S_x = noise2_x, S_y = noise2_y, S_z = noise2_z, signal_rfft = noise2_rfft[:, i]) # 接受第三个信号源\n",
    "    \n",
    "    # 先抽取处理前的信号， 好做对比\n",
    "    micAudio[:,i] = cma100.build_signal_rfft()\n",
    "\n",
    "    # beamforming\n",
    "    cma100.beamforming(audio_x, audio_y, audio_z)\n",
    "    enhancedAudio[:,i] = cma100.build_signal_rfft()\n",
    "\n",
    "enhancedAudio = librosa.istft(enhancedAudio, n_fft=512, win_length=512, hop_length=128)\n",
    "micAudio = librosa.istft(micAudio, n_fft=512, win_length=512, hop_length=128)\n",
    "enhancedAudio = NormAmplitude(enhancedAudio)\n",
    "micAudio = NormAmplitude(micAudio)\n",
    "\n",
    "# 保存数据\n",
    "soundfile.write(\"./bf_input.wav\", micAudio, samplerate=16000)\n",
    "soundfile.write(\"./bf_output.wav\", enhancedAudio, samplerate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置我们信号源位置。\n",
    "audio_x, audio_y, audio_z = 2.0, 0.0, 0.0\n",
    "noise1_x, noise1_y, noise1_z = -1.4, -1.4, 0.0\n",
    "noise2_x, noise2_y, noise2_z = -2.0, 0.0, 0.0\n",
    "\n",
    "# 初始化cma100阵列\n",
    "cma100 = CMA100(fs= 16000, L=512)\n",
    "\n",
    "# 模拟阵列流式接受信号， 并处理的过程\n",
    "frameLength = 512\n",
    "N = audio_rfft.shape[1]\n",
    "enhancedAudio = np.zeros_like(audio_rfft)\n",
    "micAudio = np.zeros_like(audio_rfft)\n",
    "\n",
    "# 流式处理：\n",
    "for i in range(N):\n",
    "    cma100.reset()\n",
    "    cma100.add_signal(S_x = audio_x, S_y = audio_y, S_z = audio_z, signal_rfft = audio_rfft[:, i]) # 接受第一个信号源\n",
    "    cma100.add_signal(S_x = noise1_x, S_y = noise1_y, S_z = noise1_z, signal_rfft = noise1_rfft[:, i]) # 接受第二个信号源\n",
    "    cma100.add_signal(S_x = noise2_x, S_y = noise2_y, S_z = noise2_z, signal_rfft = noise2_rfft[:, i]) # 接受第三个信号源\n",
    "    \n",
    "    # 先抽取处理前的信号， 好做对比\n",
    "    micAudio[:,i] = cma100.build_signal_rfft()\n",
    "    cma100.band_filter() # 频点分配\n",
    "\n",
    "    # beamforming\n",
    "    cma100.beamforming(audio_x, audio_y, audio_z)\n",
    "    enhancedAudio[:,i] = cma100.build_signal_rfft()\n",
    "\n",
    "enhancedAudio = librosa.istft(enhancedAudio, n_fft=512, win_length=512, hop_length=128)\n",
    "micAudio = librosa.istft(micAudio, n_fft=512, win_length=512, hop_length=128)\n",
    "enhancedAudio = NormAmplitude(enhancedAudio)\n",
    "micAudio = NormAmplitude(micAudio)\n",
    "\n",
    "# 保存数据\n",
    "soundfile.write(\"./bf_input.wav\", micAudio, samplerate=16000)\n",
    "soundfile.write(\"./bf_output.wav\", enhancedAudio, samplerate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('audio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73eab14e7367099ba4d8bb94d37e19591868763df968cfcf9527d45d99964ddf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
